{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PubMed RCT - Entrenamiento con MLflow\n",
        "\n",
        "**entrenar modelos** y registrar en **MLflow** (servidor en EC2).\n",
        "\n",
        "- **MLflow**: tracking en `http://54.205.108.123:5000`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab detected\n"
          ]
        }
      ],
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    print(\"Colab detected\")\n",
        "else:\n",
        "    print(\"Not Colab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlflow instalado\n",
            "transformers ya instalado\n",
            "torch ya instalado\n",
            "scikit-learn ya instalado\n",
            "accelerate ya instalado\n",
            "MLflow tracking URI: http://54.205.108.123:5000\n",
            "Listo.\n"
          ]
        }
      ],
      "source": [
        "# 1. Instalar dependencias primero (Colab), luego configurar MLflow\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = ['mlflow', 'transformers', 'torch', 'scikit-learn', 'accelerate']\n",
        "for pkg in packages:\n",
        "    try:\n",
        "        __import__('sklearn' if pkg == 'scikit-learn' else pkg)\n",
        "        print(f\"{pkg} ya instalado\")\n",
        "    except ImportError:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg, '-q'])\n",
        "        print(f\"{pkg} instalado\")\n",
        "\n",
        "import mlflow\n",
        "MLFLOW_TRACKING_URI = \"http://54.205.108.123:5000\"\n",
        "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
        "print(f\"MLflow tracking URI: {mlflow.get_tracking_uri()}\")\n",
        "print(\"Listo.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# 2. Imports\n",
        "import os\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    f1_score,\n",
        "    precision_recall_fscore_support,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import mlflow\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cargando PubMed RCT...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1df953fd63c640938667284f1cab0764",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/646 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c69de014dca46f68206bd616a508da6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dataset_infos.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d35a7ddb3514c6988f5c64898a52b2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train.jsonl:   0%|          | 0.00/40.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a56c9d73df084e65aba84af043be3687",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dev.jsonl: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2878ff8bb5154bee8433e1ba8e65fbb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test.jsonl: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e6e8e8f2d43458382da558c306010a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/176642 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7440ebe22afa40b6a6e91cce410af43e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/29672 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a933319ce11140ff8093d2cc46d347e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/29578 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n",
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 176,642 | Val: 29,672 | Test: 29,578\n",
            "Etiquetas: ['background', 'conclusions', 'methods', 'objective', 'results']\n"
          ]
        }
      ],
      "source": [
        "# 3. Cargar dataset y mapeo de etiquetas\n",
        "print(\"Cargando PubMed RCT...\")\n",
        "train_dataset = load_dataset(\"armanc/pubmed-rct20k\", split=\"train\")\n",
        "val_dataset = load_dataset(\"armanc/pubmed-rct20k\", split=\"validation\")\n",
        "test_dataset = load_dataset(\"armanc/pubmed-rct20k\", split=\"test\")\n",
        "\n",
        "unique_labels = sorted(set(train_dataset['label']))\n",
        "label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "id2label = {idx: label for label, idx in label2id.items()}\n",
        "num_labels = len(unique_labels)\n",
        "\n",
        "print(f\"Train: {len(train_dataset):,} | Val: {len(val_dataset):,} | Test: {len(test_dataset):,}\")\n",
        "print(f\"Etiquetas: {list(label2id.keys())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Downsampling por clase (opcional)\n",
        "def downsample_dataset_by_class(dataset, max_sentences_per_class=3, balance_to_min_class=False, seed=42):\n",
        "    random.seed(seed)\n",
        "    abstract_class_sentences = defaultdict(list)\n",
        "    class_all_indices = defaultdict(list)\n",
        "    for idx, ex in enumerate(dataset):\n",
        "        key = (ex['abstract_id'], ex['label'])\n",
        "        info = {'index': idx, 'sentence_id': ex.get('sentence_id', idx), 'text': ex.get('text', '')}\n",
        "        abstract_class_sentences[key].append(info)\n",
        "        class_all_indices[ex['label']].append(info)\n",
        "    selected_indices = []\n",
        "    if balance_to_min_class:\n",
        "        min_size = min(len(v) for v in class_all_indices.values())\n",
        "        for label, sentences in class_all_indices.items():\n",
        "            selected = sentences if len(sentences) <= min_size else random.sample(sentences, min_size)\n",
        "            selected_indices.extend([s['index'] for s in selected])\n",
        "    else:\n",
        "        for (_, _), sentences in abstract_class_sentences.items():\n",
        "            if len(sentences) <= max_sentences_per_class:\n",
        "                selected_indices.extend([s['index'] for s in sentences])\n",
        "            else:\n",
        "                selected_indices.extend([s['index'] for s in random.sample(sentences, max_sentences_per_class)])\n",
        "    selected_indices.sort()\n",
        "    return selected_indices\n",
        "\n",
        "def get_downsampled_dataset(dataset, max_sentences_per_class=3, balance_to_min_class=False, seed=42):\n",
        "    indices = downsample_dataset_by_class(dataset, max_sentences_per_class, balance_to_min_class, seed)\n",
        "    return dataset.select(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train completo: 176,642 | Downsampled: 69,190\n"
          ]
        }
      ],
      "source": [
        "# 5. Crear dataset downsampled (para use_downsampling=True)\n",
        "downsampled_train = get_downsampled_dataset(train_dataset, balance_to_min_class=True, seed=42)\n",
        "print(f\"Train completo: {len(train_dataset):,} | Downsampled: {len(downsampled_train):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Dataset PyTorch para el Trainer\n",
        "class SentenceLevelDataset(Dataset):\n",
        "    def __init__(self, hf_dataset, tokenizer, max_length=128):\n",
        "        self.dataset = hf_dataset\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.dataset[idx]\n",
        "        text = ex['text']\n",
        "        label = ex['label']\n",
        "        label_id = label2id[label] if isinstance(label, str) else label\n",
        "        enc = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
        "        return {\n",
        "            'input_ids': enc['input_ids'].squeeze(),\n",
        "            'attention_mask': enc['attention_mask'].squeeze(),\n",
        "            'labels': torch.tensor(label_id, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. M칠tricas para el Trainer\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(axis=-1)\n",
        "    macro_f1 = f1_score(labels, preds, average='macro')\n",
        "    micro_f1 = f1_score(labels, preds, average='micro')\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=None, labels=range(num_labels))\n",
        "    metrics = {'macro_f1': macro_f1, 'micro_f1': micro_f1}\n",
        "    for idx, name in id2label.items():\n",
        "        if idx < len(precision):\n",
        "            metrics[f'precision_{name}'] = precision[idx]\n",
        "            metrics[f'f1_{name}'] = f1[idx]\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Funci칩n de entrenamiento con MLflow\n",
        "def train_model(\n",
        "    model_name: str,\n",
        "    learning_rate: float = 2e-5,\n",
        "    batch_size: int = 16,\n",
        "    num_epochs: int = 3,\n",
        "    max_length: int = 128,\n",
        "    experiment_name: str = \"microproyecto-entrega-Nata\",\n",
        "    use_downsampling: bool = False,\n",
        "    training_dataset=None,\n",
        "):\n",
        "    mlflow.set_experiment(experiment_name)\n",
        "    training_data = training_dataset if training_dataset is not None else (downsampled_train if use_downsampling else train_dataset)\n",
        "\n",
        "    author = \"Juan Pablo Perez\"\n",
        "    strategy = \"downsampling\" if use_downsampling else \"baseline\"\n",
        "    model_short = model_name.split(\"/\")[-1]\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    run_name = f\"{author}-{strategy}-{model_short}-{timestamp}\"\n",
        "\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        mlflow.log_param(\"model_name\", model_name)\n",
        "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
        "        mlflow.log_param(\"batch_size\", batch_size)\n",
        "        mlflow.log_param(\"num_epochs\", num_epochs)\n",
        "        mlflow.log_param(\"max_length\", max_length)\n",
        "        mlflow.log_param(\"use_downsampling\", use_downsampling)\n",
        "        mlflow.log_param(\"train_size\", len(training_data))\n",
        "\n",
        "        print(f\"Training: {model_name} | samples: {len(training_data):,}\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels, id2label=id2label, label2id=label2id)\n",
        "        train_ds = SentenceLevelDataset(training_data, tokenizer, max_length)\n",
        "        val_ds = SentenceLevelDataset(val_dataset, tokenizer, max_length)\n",
        "        test_ds = SentenceLevelDataset(test_dataset, tokenizer, max_length)\n",
        "\n",
        "        output_dir = f\"./results/{model_name.replace('/', '_')}\"\n",
        "        args = TrainingArguments(\n",
        "            output_dir=output_dir,\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            learning_rate=learning_rate,\n",
        "            per_device_train_batch_size=batch_size,\n",
        "            per_device_eval_batch_size=batch_size,\n",
        "            num_train_epochs=num_epochs,\n",
        "            weight_decay=0.01,\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"macro_f1\",\n",
        "            greater_is_better=True,\n",
        "            push_to_hub=False,\n",
        "            logging_steps=100,\n",
        "            report_to=[\"none\"],\n",
        "            save_total_limit=2,\n",
        "        )\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=args,\n",
        "            train_dataset=train_ds,\n",
        "            eval_dataset=val_ds,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "        )\n",
        "        train_result = trainer.train()\n",
        "        mlflow.log_metrics({\"train_loss\": train_result.training_loss, \"train_runtime\": train_result.metrics[\"train_runtime\"], \"train_samples_per_second\": train_result.metrics[\"train_samples_per_second\"]})\n",
        "\n",
        "        val_metrics = trainer.evaluate()\n",
        "        for k, v in val_metrics.items():\n",
        "            if k.startswith(\"eval_\"):\n",
        "                mlflow.log_metric(f\"val_{k[5:]}\", v)\n",
        "        test_metrics = trainer.evaluate(test_ds)\n",
        "        for k, v in test_metrics.items():\n",
        "            if k.startswith(\"eval_\"):\n",
        "                mlflow.log_metric(f\"test_{k[5:]}\", v)\n",
        "\n",
        "        preds = trainer.predict(test_ds)\n",
        "        y_pred = preds.predictions.argmax(axis=-1)\n",
        "        y_true = preds.label_ids\n",
        "        report = classification_report(y_true, y_pred, target_names=[id2label[i] for i in range(num_labels)], digits=4)\n",
        "        print(\"\\n\" + report)\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        report_path = f\"{output_dir}/classification_report.txt\"\n",
        "        with open(report_path, 'w') as f:\n",
        "            f.write(report)\n",
        "        mlflow.log_artifact(report_path)\n",
        "\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[id2label[i] for i in range(num_labels)], yticklabels=[id2label[i] for i in range(num_labels)], ax=ax)\n",
        "        ax.set_xlabel('Predicted')\n",
        "        ax.set_ylabel('True')\n",
        "        ax.set_title(f'Confusion Matrix - {model_name}')\n",
        "        plt.tight_layout()\n",
        "        cm_path = f\"{output_dir}/confusion_matrix.png\"\n",
        "        plt.savefig(cm_path, dpi=150, bbox_inches='tight')\n",
        "        mlflow.log_artifact(cm_path)\n",
        "        plt.close()\n",
        "\n",
        "        trainer.save_model(f\"{output_dir}/model\")\n",
        "        mlflow.log_artifact(f\"{output_dir}/model\")\n",
        "        print(f\"Test macro_f1: {test_metrics['eval_macro_f1']:.4f} | micro_f1: {test_metrics['eval_micro_f1']:.4f}\")\n",
        "        return trainer, test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entrenar modelo\n",
        "\n",
        "Cada ejecuci칩n se registra en MLflow en **http://54.205.108.123:5000**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext | samples: 176,642\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf22b6a8aed0428b97163b1d030d0421",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\n",
            "Key                                        | Status     | \n",
            "-------------------------------------------+------------+-\n",
            "cls.seq_relationship.weight                | UNEXPECTED | \n",
            "cls.predictions.bias                       | UNEXPECTED | \n",
            "cls.seq_relationship.bias                  | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
            "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
            "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
            "cls.predictions.decoder.bias               | UNEXPECTED | \n",
            "cls.predictions.decoder.weight             | UNEXPECTED | \n",
            "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
            "classifier.weight                          | MISSING    | \n",
            "classifier.bias                            | MISSING    | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16563' max='16563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16563/16563 21:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Precision Background</th>\n",
              "      <th>F1 Background</th>\n",
              "      <th>Precision Conclusions</th>\n",
              "      <th>F1 Conclusions</th>\n",
              "      <th>Precision Methods</th>\n",
              "      <th>F1 Methods</th>\n",
              "      <th>Precision Objective</th>\n",
              "      <th>F1 Objective</th>\n",
              "      <th>Precision Results</th>\n",
              "      <th>F1 Results</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.355880</td>\n",
              "      <td>0.321186</td>\n",
              "      <td>0.821925</td>\n",
              "      <td>0.881976</td>\n",
              "      <td>0.627733</td>\n",
              "      <td>0.716383</td>\n",
              "      <td>0.889412</td>\n",
              "      <td>0.855978</td>\n",
              "      <td>0.953049</td>\n",
              "      <td>0.947847</td>\n",
              "      <td>0.786674</td>\n",
              "      <td>0.658674</td>\n",
              "      <td>0.924079</td>\n",
              "      <td>0.930744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.288349</td>\n",
              "      <td>0.324605</td>\n",
              "      <td>0.823513</td>\n",
              "      <td>0.883998</td>\n",
              "      <td>0.626012</td>\n",
              "      <td>0.719500</td>\n",
              "      <td>0.888863</td>\n",
              "      <td>0.851359</td>\n",
              "      <td>0.940323</td>\n",
              "      <td>0.952315</td>\n",
              "      <td>0.802758</td>\n",
              "      <td>0.662216</td>\n",
              "      <td>0.942092</td>\n",
              "      <td>0.932176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.234841</td>\n",
              "      <td>0.332446</td>\n",
              "      <td>0.830898</td>\n",
              "      <td>0.888144</td>\n",
              "      <td>0.661999</td>\n",
              "      <td>0.727833</td>\n",
              "      <td>0.880452</td>\n",
              "      <td>0.865105</td>\n",
              "      <td>0.945900</td>\n",
              "      <td>0.951853</td>\n",
              "      <td>0.781010</td>\n",
              "      <td>0.677942</td>\n",
              "      <td>0.934663</td>\n",
              "      <td>0.931757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1dd44cafc5354056859206300b0281ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07cf5b5e9163480699d8c614df1f0c75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41d992d6034b4d2ca5667b0f6616886b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias'].\n",
            "There were unexpected keys in the checkpoint model loaded: ['bert.embeddings.LayerNorm.beta', 'bert.embeddings.LayerNorm.gamma', 'bert.encoder.layer.0.attention.output.LayerNorm.beta', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma', 'bert.encoder.layer.0.output.LayerNorm.beta', 'bert.encoder.layer.0.output.LayerNorm.gamma', 'bert.encoder.layer.1.attention.output.LayerNorm.beta', 'bert.encoder.layer.1.attention.output.LayerNorm.gamma', 'bert.encoder.layer.1.output.LayerNorm.beta', 'bert.encoder.layer.1.output.LayerNorm.gamma', 'bert.encoder.layer.2.attention.output.LayerNorm.beta', 'bert.encoder.layer.2.attention.output.LayerNorm.gamma', 'bert.encoder.layer.2.output.LayerNorm.beta', 'bert.encoder.layer.2.output.LayerNorm.gamma', 'bert.encoder.layer.3.attention.output.LayerNorm.beta', 'bert.encoder.layer.3.attention.output.LayerNorm.gamma', 'bert.encoder.layer.3.output.LayerNorm.beta', 'bert.encoder.layer.3.output.LayerNorm.gamma', 'bert.encoder.layer.4.attention.output.LayerNorm.beta', 'bert.encoder.layer.4.attention.output.LayerNorm.gamma', 'bert.encoder.layer.4.output.LayerNorm.beta', 'bert.encoder.layer.4.output.LayerNorm.gamma', 'bert.encoder.layer.5.attention.output.LayerNorm.beta', 'bert.encoder.layer.5.attention.output.LayerNorm.gamma', 'bert.encoder.layer.5.output.LayerNorm.beta', 'bert.encoder.layer.5.output.LayerNorm.gamma', 'bert.encoder.layer.6.attention.output.LayerNorm.beta', 'bert.encoder.layer.6.attention.output.LayerNorm.gamma', 'bert.encoder.layer.6.output.LayerNorm.beta', 'bert.encoder.layer.6.output.LayerNorm.gamma', 'bert.encoder.layer.7.attention.output.LayerNorm.beta', 'bert.encoder.layer.7.attention.output.LayerNorm.gamma', 'bert.encoder.layer.7.output.LayerNorm.beta', 'bert.encoder.layer.7.output.LayerNorm.gamma', 'bert.encoder.layer.8.attention.output.LayerNorm.beta', 'bert.encoder.layer.8.attention.output.LayerNorm.gamma', 'bert.encoder.layer.8.output.LayerNorm.beta', 'bert.encoder.layer.8.output.LayerNorm.gamma', 'bert.encoder.layer.9.attention.output.LayerNorm.beta', 'bert.encoder.layer.9.attention.output.LayerNorm.gamma', 'bert.encoder.layer.9.output.LayerNorm.beta', 'bert.encoder.layer.9.output.LayerNorm.gamma', 'bert.encoder.layer.10.attention.output.LayerNorm.beta', 'bert.encoder.layer.10.attention.output.LayerNorm.gamma', 'bert.encoder.layer.10.output.LayerNorm.beta', 'bert.encoder.layer.10.output.LayerNorm.gamma', 'bert.encoder.layer.11.attention.output.LayerNorm.beta', 'bert.encoder.layer.11.attention.output.LayerNorm.gamma', 'bert.encoder.layer.11.output.LayerNorm.beta', 'bert.encoder.layer.11.output.LayerNorm.gamma'].\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  background     0.6662    0.7946    0.7248      3077\n",
            " conclusions     0.8696    0.8416    0.8554      4571\n",
            "     methods     0.9359    0.9565    0.9461      9884\n",
            "   objective     0.7585    0.5911    0.6644      2333\n",
            "     results     0.9313    0.9171    0.9242      9713\n",
            "\n",
            "    accuracy                         0.8801     29578\n",
            "   macro avg     0.8323    0.8202    0.8230     29578\n",
            "weighted avg     0.8821    0.8801    0.8796     29578\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3679327a873d408e99c0b89449082202",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test macro_f1: 0.8230 | micro_f1: 0.8801\n",
            "游끢 View run Juan Pablo Perez-baseline-BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext-20260222_020729 at: http://54.205.108.123:5000/#/experiments/989624885271817029/runs/efb1d2ccd421405a9cb7531d2d9e7c41\n",
            "游빍 View experiment at: http://54.205.108.123:5000/#/experiments/989624885271817029\n"
          ]
        }
      ],
      "source": [
        "# Solo cambia MODEL_NAME para probar otro modelo (no hace falta tocar el procesamiento)\n",
        "MODEL_NAME = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"  # PubMedBERT: entrenado en PubMed\n",
        "# MODEL_NAME = \"allenai/scibert_scivocab_uncased\"   # SciBERT\n",
        "# MODEL_NAME = \"bert-base-uncased\"                  # BERT general (m치s ligero)\n",
        "\n",
        "trainer, test_metrics = train_model(\n",
        "    model_name=MODEL_NAME,\n",
        "    learning_rate=2e-5,\n",
        "    batch_size=32,\n",
        "    num_epochs=3,\n",
        "    max_length=128,\n",
        "    experiment_name=\"microproyecto-entrega-Nata\",\n",
        "    use_downsampling=False,\n",
        ")\n",
        "# use_downsampling=True  -> dataset balanceado (m치s r치pido). use_downsampling=False -> baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
