# Microproyecto 1: Sequential Sentence Classification in Medical Abstracts

## Entrega 2 ‚Äì Entrenamiento con Transformers y Tracking con MLflow üöÄ

### 1. Contexto del Proyecto
En la investigaci√≥n m√©dica, los art√≠culos cient√≠ficos suelen presentarse en res√∫menes estructurados donde cada oraci√≥n cumple un rol espec√≠fico: **Background, Objective, Methods, Results o Conclusions**.

Sin embargo, muchos repositorios almacenan estos abstracts en texto plano sin segmentaci√≥n expl√≠cita, lo que dificulta:
* La revisi√≥n r√°pida de informaci√≥n cient√≠fica cr√≠tica.
* La b√∫squeda focalizada dentro de un abstract.
* El desarrollo de herramientas autom√°ticas de apoyo a investigadores.

Este proyecto aborda el problema como una tarea de **clasificaci√≥n supervisada a nivel de oraci√≥n**, utilizando modelos basados en **Transformers** para identificar autom√°ticamente el rol ret√≥rico de cada segmento en un abstract m√©dico.

**Pregunta de investigaci√≥n:**
> ¬øPuede un sistema basado en procesamiento de lenguaje natural (NLP) clasificar autom√°ticamente las oraciones de res√∫menes m√©dicos en categor√≠as ret√≥ricas que faciliten su an√°lisis y comprensi√≥n?

---

### 2. Dataset
Se utiliza el dataset **PubMed RCT 20k**, un est√°ndar en la industria disponible en Hugging Face:
üîó [armanc/pubmed-rct20k](https://huggingface.co/datasets/armanc/pubmed-rct20k)

**Caracter√≠sticas relevantes:**
* **Total de registros:** 235,892 oraciones.
* **Partici√≥n:**
    * Entrenamiento: 176,642
    * Validaci√≥n: 29,672
    * Prueba: 29,578
* **Clases (Labels):** `Background`, `Objective`, `Methods`, `Results`, `Conclusions`.

Cada registro incluye un `abstract_id` y un `sentence_id` para preservar el contexto secuencial de la publicaci√≥n original.

---

### 3. Modelo Utilizado
Para este experimento se seleccion√≥ **SciBERT** (`allenai/scibert_scivocab_uncased`), un modelo de lenguaje pre-entrenado espec√≠ficamente sobre corpus cient√≠fico de gran escala.

**Implementaci√≥n:**
En el notebook microproyecto3.ipynb se carga el modelo desde HuggingFace.
El modelo se carga mediante la librer√≠a `transformers`:
```python
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=num_labels,
    id2label=id2label,
    label2id=label2id
)
```

---

### 4. Variantes del Experimento
Se evaluaron dos configuraciones base del modelo SciBERT para analizar el impacto del desbalance de clases y la eficiencia del entrenamiento:

| Par√°metro | Variante 1 (Baseline) | Variante 2 (Downsampling) |
| :--- | :--- | :--- |
| **Learning Rate** | 2e-5 | 2e-5 |
| **Batch Size** | 32 | 32 |
| **Epochs** | 3 | 3 |
| **Max Length** | 128 | 128 |
| **Downsampling** | ‚ùå Desactivado | ‚úÖ Activado |

---

### 5. Arquitectura del Proyecto
El flujo de trabajo sigue principios de **MLOps**

**Componentes:**
* **Entrenamiento:** Google Colab (utilizando aceleraci√≥n por GPU).
* **Tracking de Experimentos:** Servidor MLflow desplegado en **AWS EC2**.
* **Backend Store:** Sistema de archivos local en la instancia.
* **Versionamiento:** Git para c√≥digo y **DVC** para datos.
* **Almacenamiento de Datos:** Amazon S3 (seg√∫n la arquitectura de la Entrega 1).

**Flujo de Trabajo:**
`Google Colab (SciBERT Training)` ‚ûî `AWS EC2 (MLflow Tracking Server)` ‚ûî `UI Web (Visualizaci√≥n de Runs)`

> **Nota:** La instancia EC2 funciona exclusivamente como servidor de tracking y almacenamiento de metadatos; no realiza el procesamiento del entrenamiento.

---

### 6. Configuraci√≥n del MLflow Tracking Server
El servidor MLflow se ejecuta en una instancia **EC2 Ubuntu t3.micro**. Se utiliza el siguiente comando para asegurar que el servicio permanezca activo en segundo plano:

```bash
nohup mlflow server \
  --host 0.0.0.0 \
  --port 5000 \
  --allowed-hosts '*' \
  --backend-store-uri file:/home/ubuntu/dvc-proj/mlruns \
  --default-artifact-root file:/home/ubuntu/dvc-proj/mlruns \
  > ~/mlflow_5000.log 2>&1 &

# Guardar el PID para gesti√≥n del proceso
echo $! | tee ~/mlflow_5000.pid

URL del tracking server: http://54.205.108.123:5000
```

---

### 7. Configuraci√≥n en Google Colab
Antes de entrenar, cada integrante debe configurar el tracking URI (Ejecutar este primer fragmento en colab):

```python
import os
import mlflow

# Configuraci√≥n de conexi√≥n remota (Reemplazar VMIP por la IP p√∫blica de la instancia)
MLFLOW_TRACKING_URI = "http://54.205.108.123:5000"
os.environ["MLFLOW_TRACKING_URI"] = MLFLOW_TRACKING_URI
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)

# Definici√≥n del experimento en el servidor
mlflow.set_experiment("pubmed-rct-classification")

print("Tracking URI activo:", mlflow.get_tracking_uri())
```

### 8. M√©tricas y Artefactos Registrados üìä
Durante el proceso de entrenamiento y evaluaci√≥n, se registran autom√°ticamente en el servidor de **MLflow** los siguientes par√°metros y archivos para asegurar la trazabilidad del experimento:

* **M√©tricas de Rendimiento:** `train_loss`, `train_runtime`, `train_samples_per_second`.
* **M√©tricas de Validaci√≥n y Test:** `val_macro_f1`, `val_micro_f1`, `test_macro_f1`, `test_micro_f1`.
* **Artefactos (Files):**
    * `classification_report.txt`: Reporte detallado con precisi√≥n, recall y puntuaci√≥n F1 por cada clase.
    * `confusion_matrix.png`: Matriz de confusi√≥n visual para identificar errores sistem√°ticos del modelo.
    * **Modelo Entrenado:** Registro de los pesos y la configuraci√≥n del Transformer para facilitar su despliegue futuro.

---

### 9. Reproducibilidad y Colaboraci√≥n
Este proyecto integra herramientas est√°ndar de la industria para garantizar un ciclo de vida de **MLOps** robusto y transparente:

1.  **Git:** Control de versiones exhaustivo del c√≥digo fuente y notebooks.
2.  **DVC + S3:** Gesti√≥n y versionamiento de datasets de gran volumen, permitiendo que cualquier integrante del equipo recupere la versi√≥n exacta de los datos utilizados.
3.  **MLflow:** Centralizaci√≥n de resultados, lo que permite la comparaci√≥n objetiva entre variantes y la auditor√≠a de hiperpar√°metros.

Esta estructura asegura la **trazabilidad completa** de los experimentos, elimina el problema de "funciona en mi m√°quina" y facilita el trabajo colaborativo dentro del equipo de investigaci√≥n.
